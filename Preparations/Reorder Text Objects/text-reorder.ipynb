{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install gdown\n\n!gdown 12ni2gB-qTQIUp2H8Fgc5gzINW0o2Zw6z","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-26T10:43:17.455308Z","iopub.execute_input":"2024-09-26T10:43:17.455592Z","iopub.status.idle":"2024-09-26T10:43:42.736884Z","shell.execute_reply.started":"2024-09-26T10:43:17.455560Z","shell.execute_reply":"2024-09-26T10:43:42.735968Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.15.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.4)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.7.4)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\nInstalling collected packages: gdown\nSuccessfully installed gdown-5.2.0\nDownloading...\nFrom: https://drive.google.com/uc?id=19HN7FVLErujMFA7rV4k3i7fdFMS_2A7b\nTo: /kaggle/working/3.csv\n100%|███████████████████████████████████████| 1.85M/1.85M [00:00<00:00, 148MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1SxGUMpEvwHxQUsoqlEah8xKLUifYtzkx\nTo: /kaggle/working/4.csv\n100%|████████████████████████████████████████| 179k/179k [00:00<00:00, 74.3MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import login\n\n# Define your Hugging Face token\nHUGGINGFACE_TOKEN = \"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\"\nlogin(token=HUGGINGFACE_TOKEN)","metadata":{"execution":{"iopub.status.busy":"2024-09-26T10:43:48.743954Z","iopub.execute_input":"2024-09-26T10:43:48.744396Z","iopub.status.idle":"2024-09-26T10:43:49.267473Z","shell.execute_reply.started":"2024-09-26T10:43:48.744356Z","shell.execute_reply":"2024-09-26T10:43:49.266585Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: read).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"import transformers\nimport torch\ntorch.backends.cuda.enable_mem_efficient_sdp(False)\n\nmodel_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n\npipeline = transformers.pipeline(\n    \"text-generation\",\n    model=model_id,\n    model_kwargs={\"torch_dtype\": torch.bfloat16},\n    device_map=\"auto\",\n)\n\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n    {\"role\": \"user\", \"content\": \"Who are you?\"},\n]\n\nterminators = [\n    pipeline.tokenizer.eos_token_id,\n    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n]\n","metadata":{"execution":{"iopub.status.busy":"2024-09-26T10:43:59.146727Z","iopub.execute_input":"2024-09-26T10:43:59.147172Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59e1ea9ea3724a378753e335ea2ea4e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a66e1667a1b4675ab742330e9da414d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c82b4bf38134d4695dca48868848b6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffa41908871347b9a257ebc84d24df73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5520b48ac1e0468b997f7d7511484f22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8429dce3fe38401caf5d3b41a7a90f8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3933539c8c704d40b610c01268b6591c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bbf6315ebb345f88c98fc4a660e446e"}},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\ndf=pd.read_csv(\"new_objects.csv\")\ndef edit_cap(item):\n    item=item.split(\" \")\n    item=list(filter(lambda a: a != \"\", item))\n    return \" \".join(item)\ndef len_cap(item):\n    item=item.split(\" \")\n    item=list(filter(lambda a: a != \"\", item))\n    return len(item)\ndef count_obj(item):\n    item_list=item[1:-2].replace(\"\\'\",\"\").replace(\" \",\"\").split(\",\")\n    return len(item_list)\ndf[\"no_objects\"]=df[\"new_objects\"].apply(count_obj)\ndf[\"len_captions\"]=df[\"captions\"].apply(len_cap)\ndf[\"edited_captions\"]=df[\"captions\"].apply(edit_cap)\ndf=df[df[\"no_objects\"]==8]\ni=0\nsubset=25000\ncap_set=set()\nImgId_cap_df=df[[\"image_ids_ref\",\"edited_captions\"]].iloc[i*subset:(i+1)*subset]\ncap_Img_id_dict={}\nfor item in ImgId_cap_df.iterrows():\n    cap_set.add(item[1][\"edited_captions\"])\n    cap_Img_id_dict[item[1][\"edited_captions\"]]=item[1][\"image_ids_ref\"]","metadata":{"execution":{"iopub.status.busy":"2024-09-01T21:14:39.360286Z","iopub.execute_input":"2024-09-01T21:14:39.361231Z","iopub.status.idle":"2024-09-01T21:14:45.656277Z","shell.execute_reply.started":"2024-09-01T21:14:39.361188Z","shell.execute_reply":"2024-09-01T21:14:45.655411Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def save_results(outputs,count):\n    object_extracted_dict={\"image_ids\":[],\"captions\":[],\n                           #\"objects\":[],\n                           \"reordered_cap\":[]}\n    for i in range(len(outputs)):\n        for j in range(len(outputs[i])):\n            cap=outputs[i][j][0][\"generated_text\"][1][\"content\"]\n            img_id=cap_Img_id_dict[cap]\n            reordered_cap=outputs[i][j][0][\"generated_text\"][2][\"content\"].split(\"assistant\\n\\n\")[-1].split(\", \")\n            object_extracted_dict[\"image_ids\"].append(img_id)\n            object_extracted_dict[\"captions\"].append(cap)\n            object_extracted_dict[\"reordered_cap\"].append(reordered_cap)\n    pd.DataFrame.from_dict(object_extracted_dict).to_csv(f\"objects_seperated_{count}.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-26T10:54:45.250601Z","iopub.execute_input":"2024-09-26T10:54:45.250870Z","iopub.status.idle":"2024-09-26T10:54:45.263527Z","shell.execute_reply.started":"2024-09-26T10:54:45.250839Z","shell.execute_reply":"2024-09-26T10:54:45.262685Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"terminators = [\n            pipeline.tokenizer.eos_token_id,\n            pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n         ]\nbatch_size=16\n\npipeline.tokenizer.pad_token_id = pipeline.model.config.eos_token_id\noutputs=[]\nimport time\nsave_interval=10000\nstart_time = time.time()\nsave_iter=0\nfor i in range(0,len(cap_Img_id_dict.keys()),batch_size):\n    save_iter+=batch_size\n    captions=list(cap_Img_id_dict.keys())[i:i+batch_size]\n    prompt_list=[]\n    for caption in captions:\n#         message = [\n#             #{\"role\": \"system\", \"content\": \"Your are object dector but in the text context instead of image\\\n#             #  just give the objects without adjectives in the sentence with comma seperated and nothing more.\"},\n#             {\"role\": \"system\", \"content\": \"You are an object detector in the context of text.\\\n#              just name objects in the text without their adjectives or anything extra in the sentences with commas separated and nothing more.\"},\n#             {\"role\": \"user\", \"content\": f\"{caption}\"}\n#         ]\n          message = [\n             {\"role\": \"system\", \"content\": \"First, identify objects in the text.\\\n             then reorder the text by replacing identified objects so that the semantics and meaning\\\n             of the new text exactly match the refrence text. Just output the reordered sentence and nothing else. for example :\\\n             a bicycle replica with a clock as the front wheel. ==> a clock as the front wheel of a bicycle replica.\\\n             a bathroom sink with toiletries on the counter. ==> toiletries on the counter of a bathroom sink.\\\n             city street with parked cars and a bench. ==> a bench and city street with parked cars.\\\n             this is an open box containing four cucumbers. ==> four cucumbers in an open box.\"},\n             {\"role\": \"user\", \"content\": f\"{caption}\"}\n         ]\n          prompt_list.append(message)\n    outputs.append( pipeline(\n     prompt_list,\n     max_new_tokens=50,\n     eos_token_id=terminators,\n     do_sample=True,\n     temperature=0.2,\n     top_p=0.9,\n     batch_size=batch_size))\n    test_outputs=outputs\n    if (i+batch_size)>=len(cap_Img_id_dict.keys()):\n        print(\"last batch\")\n        save_results(outputs,len(cap_Img_id_dict.keys())-1)\n        save_iter=0\n        outputs=[]\n    elif save_iter>=save_interval:\n        save_results(outputs,i+batch_size-1)\n        save_iter=0\n        outputs=[]\n    \nprint(\"---iter %s seconds ---\" % (time.time() - start_time))","metadata":{"execution":{"iopub.status.busy":"2024-09-01T21:14:45.669038Z","iopub.execute_input":"2024-09-01T21:14:45.669320Z","iopub.status.idle":"2024-09-01T21:17:53.054554Z","shell.execute_reply.started":"2024-09-01T21:14:45.669289Z","shell.execute_reply":"2024-09-01T21:17:53.053514Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\nA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\nSetting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\nA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\nSetting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\nA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\nSetting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\nA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\nSetting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\nA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","output_type":"stream"},{"name":"stdout","text":"last batch\n---iter 187.3707902431488 seconds ---\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}