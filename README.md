# CLIP Under the Microscope: A Fine-Grained Analysis

This repository contains the implementation and experimental analysis for our research on CLIP (Contrastive Language-Image Pre-training) model, focusing on a detailed examination of its multi-object understanding capabilities.

## ğŸ“‹ Project Overview

This research project aims to provide a comprehensive analysis of CLIP's behavior, particularly focusing on:
- Image Encoder analysis and experiments
- Text Encoder analysis and experiments
- Multi-object understanding capabilities
- Fine-grained behavioral analysis

## ğŸ—‚ï¸ Repository Structure

```
.
â”œâ”€â”€ Image Encoder Experiments/   # Experiments focused on CLIP's image encoder
â”œâ”€â”€ Text Encoder Experiments/    # Experiments focused on CLIP's text encoder
â””â”€â”€ Preparations/               # Setup and preparation scripts
```

## ğŸš€ Getting Started

### Prerequisites
[To be added: List of required dependencies and software]

### Installation
[To be added: Installation instructions]

## ğŸ§ª Running Experiments

Detailed instructions for running experiments can be found in their respective directories:
- Image Encoder experiments in `/Image Encoder Experiments`
- Text Encoder experiments in `/Text Encoder Experiments`

## ğŸ“š Documentation

For a complete understanding of our research methodology and findings, please refer to our paper included in this repository.

## ğŸ‘¥ Contributors
- Reza Abbasi
- Ali Nazari
- Aminreza Sefid
- Mohammadali Banayeeanzade
- Mohammad Hossein Rohban
- Mahdieh Soleymani Baghshah

## ğŸ“„ License

[To be added: License information]

## ğŸ“¬ Contact

[To be added: Contact information]

## ğŸ”— References

- [CLIP Under the Microscope](https://arxiv.org/pdf/2502.19842)
