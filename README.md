# CLIP Under the Microscope: A Fine-Grained Analysis

This repository contains the implementation and experimental analysis for our research on CLIP (Contrastive Language-Image Pre-training) model, focusing on a detailed examination of its multi-object understanding capabilities.

## 📋 Project Overview

This research project aims to provide a comprehensive analysis of CLIP's behavior, particularly focusing on:
- Image Encoder analysis and experiments
- Text Encoder analysis and experiments
- Multi-object understanding capabilities
- Fine-grained behavioral analysis

## 🗂️ Repository Structure

```
.
├── Image Encoder Experiments/   # Experiments focused on CLIP's image encoder
├── Text Encoder Experiments/    # Experiments focused on CLIP's text encoder
└── Preparations/               # Setup and preparation scripts
```

## 🚀 Getting Started

### Prerequisites
[To be added: List of required dependencies and software]

### Installation
[To be added: Installation instructions]

## 🧪 Running Experiments

Detailed instructions for running experiments can be found in their respective directories:
- Image Encoder experiments in `/Image Encoder Experiments`
- Text Encoder experiments in `/Text Encoder Experiments`

## 📚 Documentation

For a complete understanding of our research methodology and findings, please refer to our paper included in this repository.

## 👥 Contributors
- Reza Abbasi
- Ali Nazari
- Aminreza Sefid
- Mohammadali Banayeeanzade
- Mohammad Hossein Rohban
- Mahdieh Soleymani Baghshah

## 📄 License

[To be added: License information]

## 📬 Contact

[To be added: Contact information]

## 🔗 References

- [CLIP Under the Microscope](https://arxiv.org/pdf/2502.19842)
